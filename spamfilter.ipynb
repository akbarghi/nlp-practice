{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spamfilter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sd4N5YoudCI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb4cc048-c3f4-43dc-c237-7071b882ab3e"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB4-8qkFwdUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "4715a52c-27ee-4bd3-9054-efd641c3e3ce"
      },
      "source": [
        "import pandas as pd \n",
        "#dataframe import\n",
        "df_spam=pd.read_csv('gdrive/My Drive/Colab Notebooks/spam.csv', header=None,  encoding='latin-1')\n",
        "df_ham=pd.read_csv('gdrive/My Drive/Colab Notebooks/ham.csv', header=None, encoding='latin-1')\n",
        "\n",
        "#dataframe row column selector\n",
        "df_spam = df_spam.loc[:, 0:0]\n",
        "df_ham = df_ham.loc[:, 0:0]\n",
        "\n",
        "print(df_spam)\n",
        "print(df_ham)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                      0\n",
            "0     Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "1     FreeMsg Hey there darling it's been 3 week's n...\n",
            "2     WINNER!! As a valued network customer you have...\n",
            "3     Had your mobile 11 months or more? U R entitle...\n",
            "4     SIX chances to win CASH! From 100 to 20,000 po...\n",
            "...                                                 ...\n",
            "5044                                                NaN\n",
            "5045                                                NaN\n",
            "5046                                                NaN\n",
            "5047                                                NaN\n",
            "5048                                                NaN\n",
            "\n",
            "[5049 rows x 1 columns]\n",
            "                                                      0\n",
            "0     Go until jurong point, crazy.. Available only ...\n",
            "1                         Ok lar... Joking wif u oni...\n",
            "2     U dun say so early hor... U c already then say...\n",
            "3     Nah I don't think he goes to usf, he lives aro...\n",
            "4     Even my brother is not like to speak with me. ...\n",
            "...                                                 ...\n",
            "5044                                                NaN\n",
            "5045                                                NaN\n",
            "5046                                                NaN\n",
            "5047                                                NaN\n",
            "5048                                                NaN\n",
            "\n",
            "[5049 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9nEGR-00xNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "07fc2976-f9cb-49b7-c2b6-f4deb2a97121"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import nltk\n",
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import NaiveBayesClassifier, classify\n",
        " \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stoplist = stopwords.words('english')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOQXaap40-Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_lists(folder):\n",
        "    key_list = []\n",
        "    file_content = os.listdir(folder)\n",
        "    for a_file in file_content:\n",
        "        f = open(folder + a_file, 'r')\n",
        "        key_list.append(f.read())\n",
        "    f.close()\n",
        "    return key_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c65i038u1K_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(str(sentence, errors='ignore'))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5SzC8Lm1SI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(text, setting):\n",
        "    if setting=='bow':\n",
        "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}\n",
        "    else:\n",
        "        return {word: True for word in preprocess(text) if not word in stoplist}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhhGSMB91VMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(features, samples_proportion):\n",
        "    train_size = int(len(features) * samples_proportion)\n",
        "    # initialise the training and test sets\n",
        "    train_set, test_set = features[:train_size], features[train_size:]\n",
        "    print ('Training set of size= ' + str(len(train_set)) + ' mails')\n",
        "    print ('Test set of size = ' + str(len(test_set)) + ' mails')\n",
        "    # train the classifier\n",
        "    classifier = NaiveBayesClassifier.train(train_set)\n",
        "    return train_set, test_set, classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESKdEFUq1VRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(train_set, test_set, classifier):\n",
        "    # test accuracy of classifier on training and test set\n",
        "    print ('Training set accuracy = ' + str(classify.accuracy(classifier, train_set)))\n",
        "    print ('Test set accuracy = ' + str(classify.accuracy(classifier, test_set)))\n",
        "    # check most informative words for the classifier\n",
        "    classifier.show_most_informative_features(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKnZO4ki1VLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "66ae7a4a-8c0a-47fc-bb20-fbe0ef494444"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # initialise the data\n",
        "    #spam = df_spam.values.tolist()\n",
        "    #ham = df_ham.values.tolist()\n",
        "    spam = df_spam.to_records(index=False)\n",
        "    ham = df_ham.to_records(index=False)\n",
        "    all_mails = [(mail, 'spam') for mail in spam]\n",
        "    all_mails += [(mail, 'ham') for mail in ham]\n",
        "    random.shuffle(all_mails)\n",
        "    print ('Corpus of size = ' + str(len(all_mails)) + ' mails')\n",
        " \n",
        "    # extract the features\n",
        "    all_features = [(get_features(mail, ''), label) for (mail, label) in all_mails]\n",
        "    print ('Fetched ' + str(len(all_features)) + ' feature sets')\n",
        " \n",
        "    # train the classifier\n",
        "    train_set, test_set, classifier = train(all_features, 0.8)\n",
        " \n",
        "    # evaluate performance\n",
        "    evaluate(train_set, test_set, classifier)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus of size = 10098 mails\n",
            "Fetched 10098 feature sets\n",
            "Training set of size= 8078 mails\n",
            "Test set of size = 2020 mails\n",
            "Training set accuracy = 0.9226293637038872\n",
            "Test set accuracy = 0.8138613861386138\n",
            "Most Informative Features\n",
            "                   8Ì€\u0000\u0000 = True             spam : ham    =     19.8 : 1.0\n",
            "                       < = True              ham : spam   =     17.4 : 1.0\n",
            "                       > = True              ham : spam   =     17.4 : 1.0\n",
            "                       & = True              ham : spam   =     15.3 : 1.0\n",
            "                    c\u0000\u0000 = True              ham : spam   =     15.3 : 1.0\n",
            "                    8\u0000\u0000 = True              ham : spam   =     13.7 : 1.0\n",
            "                       x = True              ham : spam   =     11.9 : 1.0\n",
            "                       : = True              ham : spam   =     10.6 : 1.0\n",
            "                    \u0018\u0000\u0000 = True              ham : spam   =     10.1 : 1.0\n",
            "                    =\u0000\u0000 = True              ham : spam   =      9.9 : 1.0\n",
            "                    z\u0000\u0000 = True              ham : spam   =      9.9 : 1.0\n",
            "                    1\u0000\u0000 = True              ham : spam   =      9.2 : 1.0\n",
            "                       ] = True              ham : spam   =      9.2 : 1.0\n",
            "                       ( = True              ham : spam   =      8.7 : 1.0\n",
            "                    i\u0000\u0000 = True              ham : spam   =      8.0 : 1.0\n",
            "                    ^\u0000\u0000 = True              ham : spam   =      7.8 : 1.0\n",
            "                    9\u0000\u0000 = True              ham : spam   =      7.8 : 1.0\n",
            "                    p\u0000\u0000 = True              ham : spam   =      7.8 : 1.0\n",
            "                    \u0010\u0000\u0000 = True              ham : spam   =      7.7 : 1.0\n",
            "                    0\u0000\u0000 = True              ham : spam   =      7.6 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}